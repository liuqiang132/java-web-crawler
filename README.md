# java-web-crawler
Java爬虫是一种网络爬虫技术，它通过编写程序模拟浏览器行为，自动访问网站并抓取所需数据。Java爬虫可以实现自动化采集、处理和存储海量数据，为后续的数据分析、挖掘等工作提供了基础。

## 爬虫的重要概念
 爬虫一般分为采集，处理，存储三个部分
 
## 为什么要使用爬虫呢
    1.实现私人搜索引擎
    2.获取更多的数据
    3.更好的搜索引擎优化
    4.更好的就业



## jsoup
 jsoup是一款java的HTML解析器,可直接解析某个URL地址，HTML文本内容，它提供了一套非常省力的API，可通过DOM，CSS以及类似Jquery的操作方法来取出操作数据
 jsoup的功能如下:
     1.从一个URL，文件或者字符串中解析HTML
     2.使用DOM或者CSS选择器来查找，取出数据
     3.可操作HTML元素，属性，文本
 


## selenium




## webMagic
   在WebMagic里，实现一个基本的爬虫只需要编写一个类，实现PageProcessor接口即可。这个类基本上包含了抓取一个网站，你需要写的所有代码,同时这部分还会介绍如何使用WebMagic的抽取API，以及最常见的抓取结果保存的问题。
   
## 使用注解编写爬虫
  WebMagic支持使用独有的注解风格编写一个爬虫，引入webmagic-extension包即可使用此功能。
  在注解模式下，使用一个简单对象加上注解，可以用极少的代码量就完成一个爬虫的编写。对于简单的爬虫，这样写既简单又容易理解，并且管理起来也很方便。这也是WebMagic的一大特色，我戏称它为OEM(Object/Extraction Mapping)。
  注解模式的开发方式是这样的:
         首先定义你需要抽取的数据，并编写类。
         在类上写明@TargetUrl注解，定义对哪些URL进行下载和抽取。
         在类的字段上加上@ExtractBy注解，定义这个字段使用什么方式进行抽取。
         定义结果的存储方式。